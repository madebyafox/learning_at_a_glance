mean(fp)
mean(mp)
t.test(mo-mp)
t.test(mo,mp)
mean(mo)
mean(mp)
qt(.9,21.983)
t.test(mo,mp)
qt(.9,21.983)
qt(.05,21.983)
md + qt(.05,11)*sd/sqrt(n)
md = 1;
sd = 2;
n =12
##90% ci is md +- tcrit * sd/sqrt(n)
md + qt(.05,11)*sd/sqrt(n)
qt(.05,11)
md + qt(.05,11)*(sd/sqrt(n))
lower90ci = md - qt(.05,11)*(sd/sqrt(n))
upper90ci = md + qt(.05,n-1)*(sd/sqrt(n))
lower90ci = md - qt(.05,n-1)*(sd/sqrt(n))
t.test(mo-mp,fo-fp)
var(mo-po)
var(mo-fp)
var(fo-fp)
var(mo-mp)
1-pf(8.66/6.23,11,11)
?binom.test
binom.test(c(sum(mo > 70), sum(mo < 70), .5)
binom.test(c(sum(mo > 70), sum(mo < 70), .5))
binom.test(c(sum(mo > 70), sum(mo < 70)), .5)
crit_pre  = c(22,	37,	39,	46,	63,	41,	34,	39,	44,	50,	49,	58,	49,	43,	53,	39)
crit_post =	c(53,	63,	66,	77,	89,	64,	62,	67,	72,	78,	74,	81,	75,	70,	76,	63)
trad_pre = c(	43,	60,	57,	53,	57,	44,	43,	62,	64,	47,	31,	38)
trad_post= c(75,	83,	82,	99,	91,	81,	78,	92,	94,	80,	52,	74)
t.test(crit_post-crit_pre,alternative="greater")
t.test(trad_post-trad_pre,alternative="greater")
t.test(trad_post-trad_pre)
diff(c(27.50846,36.15821))
t.test(crit_post-crit_pre,trad_post-trad_pre,alternative="greater")
t.test(crit_post-crit_pre,trad_post-trad_pre,conf.level=.8)
diff(c(26.50000,31.83333 ))
Before =  c(44,	60,	59,	62,	75,	49,	46,	76,	64,	40,	73,	46,	53)
After =	c(43,	65,	60,	61,	78,	53,	44,	75,	62,	45,	79,	47,	56)
before =  c(44,	60,	59,	62,	75,	49,	46,	76,	64,	40,	73,	46,	53)
after =	c(43,	65,	60,	61,	78,	53,	44,	75,	62,	45,	79,	47,	56)
mean(before)
sd(before)
median(before)
table(after-before)
var(after-before)
var(median)
median(after-before)
iqr(after-before)
IQR(after-before)
improvement = after-before
binom.test(c(sum(improvement > 0),sum(improvement < 0)),.5)
ncat = 100;
nanimals = (100+76)
p.hat = ncat / (nanimals)
binom
p.hat
zcrit = abs(qnorm(.25/2))
p.hat + c(-1,1)*zcrit*sqrt(p.hat*(1-p.hat)/(nanimals))
p.hat = ncat / (nanimals)
zcrit = abs(qnorm(.1/2))
p.hat + c(-1,1)*zcrit*sqrt(p.hat*(1-p.hat)/(nanimals))
scores = c(76, 55, 71, 68, 73, 73, 89, 94, 71, 72, 83, 82, 84, 75, 75, 75, 85)
seh0 = sd(scores)/sqrt(length(scores))
seh0
t.test(scores,mu=69)
t.test(scores,mu=69,conf.level = .9)
diff(c(72.69759, 80.36124))
dhat = (mean(scores)-69) / seh0
dhat
binom.test(c(sum(scores > 69),sum(scores < 69)),.5)
library(PSYC201)
z.test(scores,69,10,alternative = 'greater')
z.test(scores,69,10,alternative = 'greater')
n1 = 33
m1 = 651
s1 = 48
n2 = 8
m2 = 669
s2 = 51
s.p = sqrt((s1^2*(n1-1) + s2^2*(n2-1))/(n1+n2-2))
s.p
t = (m1-m2)/s.p / sqrt(1/n1+1/n2); #tstat
df = n1 + n2 - 2 # df
# The value of the appropriate test statistic) psych > cogsci
p = pt(-abs(t), df) #one tail
# The two-tailed p-value
p = 2*pt(-abs(t), df) #two tail: 0.6821846
p
tcrit = qt(.36/2,df)
diff((m1-m2) + c(1,-1)*tcrit*s.p*sqrt(1/n1 + 1/n2)); #39.67028
(m1-m2) / s.p; #0.1283916
n1 = 33
m1 = 651
s1 = 48
n2 = 8
m2 = 669
s2 = 51
s.p = sqrt((s1^2*(n1-1) + s2^2*(n2-1))/(n1+n2-2)); #pooled variance into sd
t = (m1-m2)/s.p / sqrt(1/n1+1/n2)
t
p = 2*pt(-abs(t), df)
p
tcrit = qt(.36/2,df)
diff((m1-m2) + c(1,-1)*tcrit*s.p*sqrt(1/n1 + 1/n2)); #39.67028
load(url('http://vulstats.ucsd.edu/data/cal1020.cleaned.Rdata'))
str(cal1020)
wheelix = substr(cal1020$Division,1,5) == 'Wheel'
nowheel = subset(cal1020,!wheelix & complete.cases(cal1020))
str(nowheel)
speedage_lm = lm(speed.mph~Age,data=nowheel)
summary(speedage_lm)
anova(speedage_lm)
qplot(nowheel$Age,nowheel$speed.mph) + abline(speedage_lm)
qplot(nowheel$Age,nowheel$speed.mph)
qplot(nowheel$Age,nowheel$speed.mph)
library(PSYC201)
library(plyr)
library(ggplot2)
library(gridExtra)
qplot(nowheel$Age,nowheel$speed.mph)
abline(speedage_lm)
summary(speedage_lm)
qplot(nowheel$Age,nowheel$speed.mph)+
geom_smooth(method=speedage_lm)
geom_smooth(method=lm)
qplot(nowheel$Age,nowheel$speed.mph)+geom_smooth(method=speedage_lm)
plot(nowheel$Age,nowheel$speed.mph)+abline(speedage_lm)
qplot(nowheel$Age,nowheel$speed.mph)+geom_smooth(speedage_lm)
qplot(nowheel$Age,nowheel$speed.mph)+theme_bw()+geom_smooth(speedage_lm)
summary(speedage_lm)
anova(speedage_lm)
str(nowheel)
speedage_lm = lm(speed.mph~Age+corral,data=nowheel)
speedage_lm
speedage_lm = lm(speed.mph~Age+as.numeric(corral),data=nowheel)
speedage_lm
plot(nowheel$corral,nowheel$speed.mph)
qplot(nowheel$corral,nowheel$speed.mph)
qplot(nowheel$corral,nowheel$Age)
speedage_lm
plot(speedage_lm)
str(nowheel)
dataM = subset(nowheel,substr(cal1020$Division,1,9) == 'M')
substr(cal1020$Division,1,9)
dataM = subset(nowheel,substr(cal1020$Division,9,9) == 'M')
dataF = subset(nowheel,substr(cal1020$Division,9,9) == 'F')
mlm = lm(speed.mph~Age)
mlm = lm(speed.mph~Age,data=dataM)
mlf = lm(speed.mph~Age,data=dataF)
mlm
mlf
mlm = lm(speed.mph~Age,data=dataM)
mlm = lm(speed.mph~Age,data=dataM)
mlm
summary(mlm)
flm = lm(speed.mph~Age,data=dataF)
summary(flm)
anova(mlm,flm)
summary(mlm)
summary(flm)
install.packages(scatterplot3d)
anova(mlm)
anova(flm)
nowheel$Division
dataM = subset(nowheel,substr(cal1020$Division,9,9) == 'M ')
dataF = subset(nowheel,substr(cal1020$Division,9,9) == 'F ')
mlm = lm(speed.mph~Age,data=dataM)
dataM = subset(nowheel,substr(cal1020$Division,9,10) == 'M ')
dataF = subset(nowheel,substr(cal1020$Division,9,10) == 'F ')
mlm = lm(speed.mph~Age,data=dataM)
flm = lm(speed.mph~Age,data=dataF)
summary(mlm)
summary(flm)
anova(mlm)
anova(flm)
summary(mlm)
summary(flm)
.24/sqrt(1-.24^2)*sqrt(194-2)
tstat = .24/sqrt(1-.24^2)*sqrt(194-2)
1-pt(3.42566,192)
(1-pt(3.42566,192))*2
tstat = (.24/sqrt(1-.24^2))*sqrt(194-2)
(1-pt(tstat,192))*2
(1-pt(tstat,192))*2
load(url("http://vulstats.ucsd.edu/data/admit.data.Rdata"))
load(url("http://vulstats.ucsd.edu/data/fieldgoals.Rdata"))
str(fieldgoals)
glm(success~yardage+week,data=fieldgoals)
load(url("http://vulstats.ucsd.edu/data/crime.data.Rdata"))
str(crime.data)
glm(Count~log(Population) + State,data=crime.data,family=poisson())
read.table(url('http://vulstats.edu/data/bodyfat.data2.txt'))
read.table(url('http://vulstats.edu/data/bodyfat.data2.txt'),header=T,sep="\t")
read.table(url('http://vulstats.ucsd.edu/data/bodyfat.data2.txt'),header=T,sep="\t")
csv = read.table(url('http://vulstats.ucsd.edu/data/bodyfat.data2.txt'),header=T,sep="\t")
csv
csv = read.table(url('http://vulstats.ucsd.edu/data/bodyfat.data2.txt'),header=T,sep="\t")
csv
csv$height
sort(csv$height)
sort(csv$height)[2]
which.max(csv$height)
sort(csv$height)[2]
sort(csv$height)[-2]
sort(csv$height)[length(csv$height)-1]
sort(csv$height)[2]
?mean
winz = function(x){
x[which.max(x)] = sort(x)[length(csv$height)-1]
x[which.min(x)] = sort(x)[2]
}
winz(csv$height)
winz(csv$height)
a = winz(csv$height)
?sample
replicate(1000,winz(sample(csv$height,length(csv$height))))
replicate(1000,winz(sample(csv$height,length(csv$height),T)))
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(2.5,97.5)
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(2.5,97.5))
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(2.5,97.5))
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.25,.975))
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.025,.975))
quantile(x,.1)
qauntile(csv$height,.1)
quantile(csv$height,.1)
winz = function(x){
x[x > quantile(x,1-.1)] = quantile(x,1-.1)
x[x > quantile(x,.1)] = quantile(x,.1)
return mean(x)
}
winz = function(x){
x[x > quantile(x,1-.1)] = quantile(x,1-.1)
x[x > quantile(x,.1)] = quantile(x,.1)
return mean(x)
}
winz = function(x){
x[x > quantile(x,1-.1)] = quantile(x,1-.1)
x[x < quantile(x,.1)] = quantile(x,.1)
return mean(x)
}
winz = function(x){
x[x > quantile(x,1-.1)] = quantile(x,1-.1)
x[x < quantile(x,.1)] = quantile(x,.1)
return mean(x);
}
winz = function(x){
x[x > quantile(x,1-.1)] = quantile(x,1-.1)
x[x < quantile(x,.1)] = quantile(x,.1)
return(mean(x))
}
quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.025,.975))
replicate(1000,winz(sample(csv$height,length(csv$height),T)))
csv$height
confint(csv$height)
winzCI
winzCI = quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.025,.975))
range(csv$height)
mean(csv$height)
winzCI = quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.025,.975))
winzCI = quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.05,.95))
winzCI = quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.05,.95))
winz = function(x){
q1 = quantile(x,1-.1)
x[x > quantile(x,1-.1)] = q1
q2 = quantile(x,.1)
x[x < quantile(x,.1)]   = q2
return(mean(x))
}
winzCI = quantile(replicate(1000,winz(sample(csv$height,length(csv$height),T))),c(.05,.95))
cornew = function(y,x){
lm1 = lm(y~x)
return(coef(lm1))
}
cornew(csv$height,csv$weight)
test = quantile(replicate(1000,cornew(csv$height,csv$weight),T))),c(.05,.95))
test = quantile(replicate(1000,cornew(csv$height,csv$weight),T),c(.05,.95))
test
b0 = quantile(replicate(1000,cornew(csv$height,csv$weight)[1],T),c(.05,.95))
replicate(1000,cornew(csv$height,csv$weight)[1],T)
csv$height
b0 = quantile(replicate(1000,cornew(sample(csv$height,length(csv$height),
sample(csv$weight,length(csv$weight))[1],T),
c(.05,.95))
cornew = function(y,x){
lm1 = lm(y~x)
return(coef(lm1))
}
b0 = quantile(replicate(1000,cornew(sample(csv$height,length(csv$height),
sample(csv$weight,length(csv$weight))))[1],T),
c(.05,.95))
b0 = quantile(replicate(1000,cornew(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight)))[1],T),
c(.05,.95))
b1 = quantile(replicate(1000,cornew(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight)))[2],T),
c(.05,.95))
cor(csv$height,csv$weight)
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
cor1 = function(y,x){
return(cor(y,x))
}
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
cor1 = function(y,x){
return(cor(y,x),method='spearman')
}
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
?cor
cor1 = function(y,x){
return(cor(x,y))
}
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
cor1 = function(y,x){
return(cor(x,y,method='spearman'))
}
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.025,.975))
b0 = quantile(replicate(1000,cornew(rbind(sample(csv$height,length(csv$height)),
sample(csv$weight,length(csv$weight))),T),
c(.05,.95))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height),T),
sample(csv$weight,length(csv$weight),T))),
c(.025,.975))
cor1 = function(x,y){
return(cor(x,y,method='spearman'))
}
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height),T),
sample(csv$weight,length(csv$weight),T)),
c(.025,.975))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height),T),
sample(csv$weight,length(csv$weight),T)),
c(.025,.975)))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height),T),
sample(csv$weight,length(csv$weight),T)),
c(.025,.975)))
cor(csv$height,csv$weight)
cor(sample(csv$height,length(csv$height),T),sample(csv$weight,length(csv$weight),T))
R = quantile(replicate(1000,cor1(sample(csv$height,length(csv$height),T),
cor(sample(csv$height,length(csv$height),T),sample(csv$weight,length(csv$weight),T))
cor(sample(csv$height,length(csv$height),T),sample(csv$weight,length(csv$weight),T))
csv = load(url('http://vulstats.ucsd.edu/data/e3.data.Rdata'))
csv
dat$r = residuals(lm(data=csv, x~as.factor(drunk)))
ls
ls()
setwd("C:/Users/me/Google Drive/code/matlab/projects/huey/analysis/data")
setwd("C:/Users/me/Google Drive/classes_meetings/HCI_f2015/Ataglance/CODE/learning_at_a_glance/analysis")
require(ggplot2)
library(plyr)
library('binom')
#library('languageR')
library('lme4')
library('arm')
library('sjPlot') #good package for plotting lmer
library("scales")
# load in all csv files
csvlist = list.files(pattern="*.csv")
for (i in 1:length(csvlist)){
tmp = read.csv(csvlist[i]);
#tmp$subjID = rep(substring(csvlist[i],1,3),times=nrow(tmp)); # add subjid to every row
#tmp = rbind(colorstim,blackstim)
if (i == 1) {
all_data = tmp;
} else {
all_data = rbind(all_data,tmp) # combine csvs into one
}
} #TODO make trial_number useful for analysis
csvlist = list.files(pattern="*learn.csv")
for (i in 1:length(csvlist)){
tmp = read.csv(csvlist[i]);
#tmp$subjID = rep(substring(csvlist[i],1,3),times=nrow(tmp)); # add subjid to every row
#tmp = rbind(colorstim,blackstim)
if (i == 1) {
all_data = tmp;
} else {
all_data = rbind(all_data,tmp) # combine csvs into one
}
} #TODO make trial_number useful for analysis
summary(all_data)
all_data$timestamp
ggplot(data=data_data, aes(x = xmousex, y = ymousey) +
geom_point()
ggplot(data=data_data, aes(x = xmousex, y = ymousey)) + geom_point()
ggplot(data=data_data, aes(x = xmousex, y = ymousey)) + geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey)) + geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=row(xmousex))) + geom_point()
seq.int(1, length(all_data)
seq.int(1, length(all_data))
seq.int(1, length(all_data))
seq.int(1, nrow(all_data))
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data))) + geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data)))) + geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data)))) + geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data))))
+ geom_point() + scale_colour_gradientn(colours = rainbow(5))
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data))))
+ geom_point() + scale_colour_gradientn(colours = rainbow(5))
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data)))) +
geom_point()
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data)))) +
geom_point() + scale_colour_gradientn(colours = rainbow)
ggplot(data=all_data, aes(x = xmousex, y = ymousey,color=seq.int(1, nrow(all_data)))) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
install.packages("saccades")
library("saccades")
detect.fixations?
??detect.fixations
data.frame('x'=all_data$xmousex)
data.frame('x'=all_data$xmousex,'y'==all_data$xmousex,'time'=seq.int(1, nrow(all_data)))
View(tmp)
fx = data.frame('x'=all_data$xmousex,'y'==all_data$xmousex,'time'=seq.int(1, nrow(all_data)))
fx = data.frame('x'=all_data$xmousex,'y'==all_data$ymousey,'time'=seq.int(1, nrow(all_data)))
fx = data.frame(x=all_data$xmousex,'y'==all_data$ymousey,'time'=seq.int(1, nrow(all_data)))
fx = data.frame(x=all_data$xmousex,y==all_data$ymousey,time=seq.int(1, nrow(all_data)))
fx = data.frame(x=all_data$xmousex,y=all_data$ymousey,time=seq.int(1, nrow(all_data)))
fx = data.frame(x=all_data$xmousex,y=all_data$ymousey,
time=seq.int(1, nrow(all_data)),trial=seq.int(1, nrow(all_data)))
detect.fixations(fx)
just_eyedata = data.frame(x=all_data$xmousex,y=all_data$ymousey,
time=seq.int(1, nrow(all_data)),trial=seq.int(1, nrow(all_data)))
fx = detect.fixations(just_eyedata)
View(fx)
fx = detect.fixations(just_eyedata,lambda = 15)
fx = detect.fixations(just_eyedata,lambda = 15)
fx = detect.fixations(just_eyedata)
fx = detect.fixations(just_eyedata,lambda = 2)
fx = detect.fixations(just_eyedata,lambda = 1)
fx = detect.fixations(just_eyedata,lambda = 5)
fx = detect.fixations(just_eyedata,lambda = 10)
fx = detect.fixations(just_eyedata,lambda = 20)
fx = detect.fixations(just_eyedata,lambda = 200)
fx = detect.fixations(just_eyedata,lambda = 50)
fx = detect.fixations(just_eyedata,lambda = 15,smooth.saccades=F)
View(fx)
View(just_eyedata)
just_eyedata = data.frame(x=all_data$xmousex,y=all_data$ymousey,
time=seq.int(1, nrow(all_data)),trial=rep.int(1, nrow(all_data)))
fx = detect.fixations(just_eyedata,lambda = 2)
View(fx)
fx = detect.fixations(just_eyedata,lambda = 15)
View(fx)
fx = detect.fixations(just_eyedata,lambda = 7)
View(fx)
diagnostic.plot(just_eyedata, fx)
fx = detect.fixations(just_eyedata,lambda = 5)
diagnostic.plot(just_eyedata, fx)
fx = detect.fixations(just_eyedata,lambda = 15)
diagnostic.plot(just_eyedata, fx)
fx = detect.fixations(just_eyedata,lambda = 20)
diagnostic.plot(just_eyedata, fx)
fx = detect.fixations(just_eyedata,lambda = 15)
diagnostic.plot(just_eyedata, fx)
ggplot(data=fx, aes(x = x, y = y,color=dur)) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur+50)) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=(dur+50))) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = rainbow(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = heat(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = hot(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point()
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = heat.colors(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = reds(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_gradientn(colours = Reds(10))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_brewer(colours=Reds())
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() + scale_colour_brewer()
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() +
scale_colour_gradientn(colours = colorRampPalette(rev(brewer.pal(11, "Spectral")))(1000))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() +
scale_colour_gradientn(colours = rev(heat.colors()))
scale_colour_gradientn(colours = rev(heat.colors(20)))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() +
scale_colour_gradientn(colours = rev(heat.colors(20)))
scale_colour_gradientn(colours = rev(rainbow(20)))
ggplot(data=fx, aes(x = x, y = y,color=dur,size=dur)) +
geom_point() +
scale_colour_gradientn(colours = rev(rainbow(20)))
